1:jdk1.5之前是thread 和 Runable，之后又callable
2；futureTask，volite修饰符， 
crtl+shift+B 全选  回车 查看继承结构图
3：多线程的目的 就是最大限度的利用cpu资源；当某一线程不需要占用cpu，而只和io等资源打交道时，让需要占用cpu的线程有机会获取cpu资源；
4：线程的实现方式：Runable，Thread，Callable
5：线程的生命周期：a:初始化:new
                              b:就绪：调用.start();这时候需要等待jvm的调度，不一定会马上执行；
                              c:运行：执行 run（） 方法；
                                                 c1：等待  wait 
                                                 c2：睡眠：sleep
                                                 c3：阻塞：blocked/  同步锁 
                              d：死亡，run执行完毕，调用stop，异常抛出 ，都会导致线程死亡；
6：让线程有序执行：join 方法；join方法可以阻塞主线程，当本线程调用完毕后继续执行；
7：wating 会释放对象锁，进入等待状态，当被唤醒时，会马上进入准备状态，获取对象锁，（wait 和 notifyall 的使用一定是多个线程对应的一个对象，同一个对象的wait与notifyall，否则会异常）
8：sleep 不会释放对象锁，一直占有，知道时间结束；
9：yeild:使用该方法有机会释放cpu资源，暗示cpu降低对该资源的调度，具体还要看cpu的调度；
10：futureTask 类里面的线程状态 0-6、
11：futrueTask 实现了runnable，和callable，构造方法可以传入这两个接口的实现类，本身实现类run方法，启动一个线程执行就好
    改方法的get方法实现了阻塞队列，可以获取线程的返回值； task.get();
12: volatile 保证修饰的变量的可见性
13：可见性（所有线程都能看到一个公共变量）；原子性（基本数据类型读取，要么成功，要么失败），有序性（保证执行顺序）
14：在多核cpu计算中，例如i= i+1；会将主存的数据读取到高速缓冲区，然后修改后赋值写会主存中，假设i=0；两个线程来执行
    那么结果是2；但是由于cpu处理速度非常快，导致在读取的i的时候两个线程读取到的都是0，导致最终结果是1；共享变量不一致的问题
15：java代码值cpu执行时，会把两个依赖的进行有序执行，不影响的分开执行提升效率，保证最终结果一致，但不保证执行顺讯一定和代码写的一致
16：synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性
17：volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作
18：锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作
19：程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
20：传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
21：线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作
22：线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
23：线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
24：对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始
25：为什么要用线程池？
26：线程越多不代表效率越高；线程越多会消耗很多时间在cpu分片与上下文切换上；
27：java中有几种线程池？普通线程池（threadPollExecotutor），定时线程池(SchduledThreadPoolExecutor)
28：ThreadPoolExecutor 有五个内部类，分为两类，policy(策略)，worker(工作)
29：线程池的体系：1：executor（执行接口），ExecutorService(提交接口)，AbstractExecutorService(把执行和提交接口合并，submit有返回值，execu 无返回值)
    ThreadPoolExecutor（调用addwork offer》task 放入队列，run方法调用runwork方法 通过getTask从队列拿数据）
    ScheduledThreadPoolExecutor（定时调度线程池），
30：内部工作原理 1:corePoolSize:池中所保存的线程数，包括空线程；
                 2：maximumPoolSize：池中允许的最大的线程数；
		 3：keepAliveTime：当线程数大于核心，此为终止前多余的空线程等待新任务的最长时间；
		 4：unit ：上面时间的单位；
		 5：workQueue：执行前用于保存任务的队列，次队列仅保持有execute方法提交的Runnable任务（不需要返回值）
		 6：threadFactory：执行程序创建新线程使用的工厂
		 7：handler：由于超出线程范围和队列容量而执行的策略
30.5：常用线程池优劣：
                 1：FixedThreadPool；
		       a:corePoolSize与maximumPoolSize相等，即其线程全为核心线程，是一个固定大小的线程池，是其优势；
		       b:keepAliveTime = 0 该参数默认对核心线程无效，而FixedThreadPool全部为核心线程
		       c:workQueue 为LinkedBlockingQueue（无界阻塞队列），队列最大值为Integer.MAX_VALUE。如果任务提交速度持续大余任务处理速度，
		       会造成队列大量阻塞。因为队列很大，很有可能在拒绝策略前，内存溢出。是其劣势
		       d:FixedThreadPool的任务执行是无序的;
		       适用场景：可用于Web服务瞬时削峰，但需注意长时间持续高峰情况造成的队列阻塞。
		 2: CachedThreadPool
		       a:corePoolSize = 0，maximumPoolSize = Integer.MAX_VALUE，即线程数量几乎无限制；
		       b:keepAliveTime = 60s，线程空闲60s后自动结束。
		       c:workQueue 为 SynchronousQueue 同步队列，这个队列类似于一个接力棒，入队出队必须同时传递，
		           因为CachedThreadPool线程创建无限制，不会有队列等待，所以使用SynchronousQueue；
		       适用场景：快速处理大量耗时较短的任务，如Netty的NIO接受请求时，可使用
		 3:SingleThreadExecutor
		       a:FixedThreadPool可以向下转型为ThreadPoolExecutor，并对其线程池进行配置，
		          而SingleThreadExecutor被包装后，无法成功向下转型。因此，SingleThreadExecutor被定以后，无法修改，做到了真正的Single
		 4:ScheduledThreadPool
		       a:newScheduledThreadPool调用的是ScheduledThreadPoolExecutor的构造方法，而ScheduledThreadPoolExecutor继承了ThreadPoolExecutor，构造是还是调用了其父类的构造方法
		       可以做定时线程调度
31：线程池运行思路 
                 1：如果当前线程吧poolSize 小于corePoolSize，则创建新线程的执行任务；
		 2：如果当前线程poolSize 大于corePoolSize，且等待队列未满，则进入等待队列；
		 3：如果当前线程pooSize 大于corePoolSize 且小于maximumPoolSize，且等待队列已满，则创建新线程
32：拒绝策略  
                 1：AbortPolicy：抛出异常，默认
		 2：CallerRunsPolicy：不使用线程池执行；
		 3：DisCardPolicy：直接丢弃任务
		 4：DiscardOldestPolicy：丢弃队列最旧的任务；
		 5：jps 》 jstack 排查线程死锁；
附：使用SynchronousQueue 不可以设置大小，开启的线程数量是由任务数量决定的
        LinkedBlockingQueue 可以设置大小，是阻塞队列，开启的线程数量根据队列的大小决定的
	future.get() 会阻塞队列，导致，CachedThreadPool的线程数量不能一直开启，失去本身的优势；
-------------------------------------------
33：JMM&Lock
34：单核cpu - 主存 只有一个 cache，现在多核的 cpu-主存 有三个cache
35：（并发处理不同步）解决缓存不一致问题：bus总线锁，缓存一致性协议，简称MESI（I7 已经不再使用 ，在这基础上扩充）；
36：MESI的四种状态；1修改，2 独享；3:共享，4 无效；
37：堆的确定由于是动态分配内存，所有存储速度回可能慢一些（需要判断内存容量是否足够，不够需要扩容，扩容需要时间）
38：栈的数据可以共享，读取速度仅次于cpu中的寄存器，非常快；主要存放基本类型变量；缺点是栈中的大小是需要事先指定，灵活性不足；
39：java并发变三个概念：原子性，可见性，有序性；
40：指令重排，Happens-before 原则，保证了 cpu执行指令虽然顺序不同，但是最终结果一致；
41： 内存同步 ：开始读取数据加lock  处理完了会写主存，释放锁；
42：数据是从主存里面读取的，读取到工作内存（副本），没有锁，多线程之间会有数据不一致问题；
43：volatile 原理就是不读工作副本，只读 主存，所以数据就是透明的，因为大家都读主存；
44：javap -i fileName.class  将class文件变成指令码；
45：volatile 不能保证原子性（例如i++  复合操作），只能保证从主存当中读的原子性，不能保证往主存中写的原子性，如果要保证原子性 ，就要用到锁（lock，Synchronized）,
46：解决原子性 方案：1 锁，2，cas
47：Synchronized，只一个重量级锁，重入锁，支持方法，代码块，（JVM级别的锁）
48：Synchronized原理：通过javap -v xxx.class 编译成指令码后，锁定方法的指令：ACC_SYNCHRONIZED，代码块 monitorenter开始，monitorexit 结束；
49：Join的底层用的wait，也是用monitorenter开始，monitorexit 结束； 做的  jvm监视器做的监控 objectMonitor() c++写的；
50：JNI 是如果调用本地的C或者C++
51： 对象锁不能保证线程安全，类锁可以（不同对象也可以保证线程安全）
52：方法和代码块（对象锁和类锁）
             1：对于普通同步方法，锁定的当前对象
	     2：对于静态方法，所得是当前类Class对象
	     3：对于同步方法快，锁是Synchonized 括号里配置的对象
53：如果想要锁住多个对象保证线程安全，那么两个办法，1 用static 锁住对象，2：用另外一个对象包含待处理的对象，当前类锁即可；
54：lock 是基于代码层级的锁，俗称隐式锁，显式锁；
55：ReetrantLock 重入锁，
56：使用lock方法 和unlock 一定要保证unlock被调用，用到finnaly
57：ReetrantLock常用的方法
             -----使用
             1：lock()
	     2: unlock();
	     3: tryLock()
	     4: lickInterruptibly
	     -----统计-----
	     5: getHoldCount
	     6: getQueuedThreads
58：Synchronized 手动的jvm级别重入锁，REentrantLock 手机动的 重入 lock指令
59：Condition
 -----
        Condition是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition，阻塞队列实际上是使用了Condition来模拟线程间协作。
	Condition是个接口，基本的方法就是await()和signal()方法；
	Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition() 
	调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用
	Conditon中的await()对应Object的wait()；
	Condition中的signal()对应Object的notify()；
	Condition中的signalAll()对应Object的notifyAll()。
60：tampedLock 悲观锁，java1.8 推出的；
61：ReecentLock 底层用的同步器，AbstarctQueueSynchroizer，并发变成核心类，俗称AQS
62：同步器AbstarctQueueSynchroizer 的实现原理就是 队列+双向链表，JUC java util concurrent；
63：CountDownLatch：允许一个线程或者多个线程 
64: Semaphore 信号量，可以用于分布式限流，针对打个jvm设置并发；
-------------atomic----
65：静态变量，线程不安全；实例变量，不安全；局部变量，线程安全；静态方法内，线程安全（里面没有静态变量）


----------------blockqueue-----------
66：线程安全非阻塞的queue：ConcurrentLinkedQueue； 基于链接节点的无界线程安全队列，非阻塞算法，基于Cas的方式来实现；
67：BlockingQueue： 线程安全，一个支持两个附加操作的队列，在队列为空时，获取元素的线程会等待队列变为非空，当队列满时，存储元素的线程会等待队列可用；
68：当多个线程都执行了wait 操作后，此时是将锁释放掉了，其他线程可以进来，因为队列满了 不能放入值，此时被继续挂起，释放锁
    一直等到队列有位置后，执行wait操作的线程被唤醒，被唤醒的wait线程是需要竞争锁的（因为他们释放的锁）；谁拿到锁了，谁就继续执行，
    拿不到的继续wait；
69：为了性能，尽可能让队列的写操作只有一个，读多个，可以创建多个队列；
70：如果一定要多个线程写，尽量使用cas
71：

    


问题1：读为什么要用锁？
